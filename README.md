# Comprehensive Artificial Intelligence Reading Compendium (Free Resources)

## üìñ Table of Contents

1. [General AI & Machine Learning Foundations](#general-ai--machine-learning-foundations)
2. [Neural Networks & Deep Learning](#neural-networks--deep-learning)
3. [Transformers & Large Language Models (LLMs)](#transformers--large-language-models-llms)
4. [Generative AI & Generative Models](#generative-ai--generative-models)
5. [Reinforcement Learning & Decision Making](#reinforcement-learning--decision-making)
6. [Symbolic AI & Automated Reasoning](#symbolic-ai--automated-reasoning)
7. [Cognitive Architectures & Cognitive Modeling](#cognitive-architectures--cognitive-modeling)
8. [Neuro-Symbolic & Hybrid AI](#neuro-symbolic--hybrid-ai)
9. [Multi-Modal AI (Vision, Language, and More)](#multi-modal-ai-vision-language-and-more)
10. [Explainability & Model Interpretability](#explainability--model-interpretability)
11. [Ethics, Safety & AI Alignment](#ethics-safety--ai-alignment)
12. [Human-AI Interaction & Collaboration](#human-ai-interaction--collaboration)

## General AI & Machine Learning Foundations
*Introductory and broad resources on AI and machine learning, suitable for building a strong foundation.*

* **[Artificial Intelligence: Foundations of Computational Agents (3rd Ed., 2023)](https://artint.info/)** ‚Äì *David L. Poole & Alan K. Mackworth*. Comprehensive HTML textbook covering intelligent agents, search, reasoning under uncertainty, planning, multi-agent systems, KR, and societal impacts.
* **[Demystifying Artificial Intelligence (2023)](https://freecomputerbooks.com/Demystifying-Artificial-Intelligence.html)** ‚Äì *Emmanuel Gillain*. Concise open-access book contrasting symbolic/statistical AI and explaining core concepts and ethics.
* **[Unlocking Artificial Intelligence (2022)](https://freecomputerbooks.com/Unlocking-Artificial-Intelligence.html)** ‚Äì *Christopher Mutschler et al.* Springer PDF on data-driven learning, uncertainty quantification, RL agents, and industrial applications.
* **[The Hundred-Page Machine Learning Book (2019)](http://themlbook.com/wiki/doku.php)** ‚Äì *Andriy Burkov*. 100-page ML primer, free PDF available under ‚Äúread first, pay later.‚Äù
* **[Machine Learning Yearning (2018)](https://www.mlyearning.org/)** ‚Äì *Andrew Ng*. Free online guide on ML project strategy: task prioritization, error analysis, validation.
* **[Introduction to Statistical Learning (2nd Ed., 2021)](https://www.statlearning.com/)** ‚Äì *Gareth James et al.* Free PDF textbook with R labs covering regression, classification, trees, clustering.
* **[Elements of Statistical Learning (2009)](https://web.stanford.edu/~hastie/ElemStatLearn/)** ‚Äì *Trevor Hastie et al.* In-depth theory book on SVMs, boosting, neural nets, available free.

## Neural Networks & Deep Learning
*Resources on neural architectures and deep learning, from intuitive introductions to comprehensive references.*

* **[Neural Networks and Deep Learning (2015)](http://neuralnetworksanddeeplearning.com/)** ‚Äì *Michael Nielsen*. Free online book with narrative explanation, visual proofs, and code walkthroughs.
* **[Deep Learning (2016)](https://www.deeplearningbook.org/)** ‚Äì *Goodfellow, Bengio & Courville*. Standard deep learning textbook, free HTML/PDF on authors‚Äô site.
* **[Dive into Deep Learning (2020)](https://d2l.ai/)** ‚Äì *Zhang et al.* Jupyter-based interactive book with MXNet, PyTorch, TensorFlow examples.
* **[A Brief Introduction to Neural Networks (2014)](https://mattmazur.com/2015/03/17/a-brief-introduction-to-neural-networks/)** ‚Äì *David Kriesel*. PDF with hand-drawn illustrations explaining perceptrons, backprop.
* **[Neural Networks (2023)](https://library.oapen.org/handle/20.500.12657/69382)** ‚Äì *Dhaliwal, Lepage-Richer & Suchman*. OAPEN book exploring neural nets‚Äô history, culture, and societal impact.
* **[Deep Learning for Coders with fastai and PyTorch (2020)](https://course.fast.ai/)** ‚Äì *Howard & Gugger*. Fast.ai‚Äôs free online book teaching practical DL via high-level API.
* **[Deep Learning with PyTorch (2020)](https://github.com/PacktPublishing/Deep-Learning-with-PyTorch)** ‚Äì *Stevens, Antiga & Viehmann*. GitHub repo for free download of PyTorch tutorial book.

## Transformers & Large Language Models (LLMs)
*Key papers and surveys on attention, transformer architectures, and modern LLM training techniques.*

* **[Attention Is All You Need (2017)](https://arxiv.org/abs/1706.03762)** ‚Äì *Vaswani et al.* Introduced the Transformer, revolutionizing sequence modeling with self-attention.
* **[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (2018)](https://arxiv.org/abs/1810.04805)** ‚Äì *Devlin et al.* Bidirectional masked LM and next-sentence prediction.
* **[Language Models are Few-Shot Learners (2020)](https://arxiv.org/abs/2005.14165)** ‚Äì *Brown et al.* GPT-3 paper showing few-shot prompting capabilities.
* **[Training Language Models to Follow Instructions with Human Feedback (2022)](https://arxiv.org/abs/2203.02155)** ‚Äì *Ouyang et al.* InstructGPT/RLHF method to align LMs to user intent.
* **[Foundations of Large Language Models (2023)](https://arxiv.org/abs/2307.09394)** ‚Äì *Tong Xiao & Jingbo Zhu*. Comprehensive survey of LLM pre-training, scaling, fine-tuning.
* **[A Survey of Large Language Models (2023)](https://arxiv.org/abs/2303.18223)** ‚Äì *Zhao et al.* RUCAIBox overview of GPT, PaLM, LLaMA, and evaluation methods.
* **[GPT-4 Technical Report (2023)](https://cdn.openai.com/papers/gpt-4.pdf)** ‚Äì *OpenAI*. Official GPT-4 capabilities and limitations.
* **[Sparks of AGI: Early Experiments with GPT-4 (2023)](https://arxiv.org/abs/2303.12712)** ‚Äì *Bubeck et al.* Empirical evaluation of GPT-4‚Äôs general intelligence.
* **[LLaMA: Open and Efficient Foundation Language Models (2023)](https://arxiv.org/abs/2302.13971)** ‚Äì *Touvron et al.* Meta‚Äôs scaled-down LLMs with competitive performance.
* **[BLOOM Language Model (2022)](https://arxiv.org/abs/2211.05100)** ‚Äì *BigScience*. 176B open-source multilingual LLM.

## Generative AI & Generative Models
*Seminal papers on GANs, VAEs, diffusion models, and state-of-the-art generative techniques.*

* **[Generative Adversarial Networks (2014)](https://arxiv.org/abs/1406.2661)** ‚Äì *Goodfellow et al.* Original GAN formulation as minimax game.
* **[CycleGAN: Unpaired Image-to-Image Translation (2017)](https://arxiv.org/abs/1703.10593)** ‚Äì *Zhu et al.* GANs for style transfer without paired data.
* **[Auto-Encoding Variational Bayes (2013)](https://arxiv.org/abs/1312.6114)** ‚Äì *Kingma & Welling*. Original VAE paper.
* **[Denoising Diffusion Probabilistic Models (2020)](https://arxiv.org/abs/2006.11239)** ‚Äì *Ho et al.* Diffusion-based generative modeling.
* **[Latent Diffusion Models (2022)](https://arxiv.org/abs/2112.10752)** ‚Äì *Rombach et al.* Stable Diffusion‚Äôs latent-space approach.
* **[Imagen & DALL¬∑E 2 (2022)](https://cdn.openai.com/papers/dall_e_2.pdf)** ‚Äì *Google Brain & OpenAI*. Reports on advanced text-to-image methods.
* **[Prompting Techniques Survey (2021)](https://arxiv.org/abs/2107.13586)** ‚Äì *Liu et al.* Systematic review of prompting methods in NLP.
* **[OpenAI Jukebox (2020)](https://arxiv.org/abs/2005.00341)** ‚Äì Music generation with transformers.
* **[AudioLM (2022)](https://arxiv.org/abs/2201.05424)** ‚Äì Token-based audio generation.

## Reinforcement Learning & Decision Making
*Core RL textbooks, landmark papers, and modern advancements.*

* **[Reinforcement Learning: An Introduction (2nd Ed., 2018)](http://incompleteideas.net/book/the-book.html)** ‚Äì *Sutton & Barto*. Definitive RL textbook, free PDF.
* **[Algorithms for Decision-Making (2022)](https://mlfa.github.io/)** ‚Äì *Kochenderfer et al.* Decision theory, planning, bandits, and RL.
* **[AlphaZero (2017)](https://arxiv.org/abs/1712.01815)** ‚Äì *Silver et al.* Self-play RL with MCTS for Chess/Shogi/Go.
* **[OpenAI Gym (2016)](https://gym.openai.com/)** ‚Äì Toolkit and example environments.
* **[Planning Algorithms (2006)](http://planning.cs.uiuc.edu/)** ‚Äì *LaValle*. Motion and discrete planning.
* **[STRIPS (1971)](https://arxiv.org/abs/1307.0865)** ‚Äì *Fikes & Nilsson*. Original planning representation.

## Symbolic AI & Automated Reasoning
*Logic-based AI, knowledge representation, classical search, and symbolic planning.*

* **[Symbolic AI Overview: A Beginner‚Äôs Guide to Symbolic Reasoning & Deep Learning (2019)](https://towardsdatascience.com/a-beginners-guide-to-symbolic-reasoning-and-deep-learning-1dea1f0d9db8)** ‚Äì *Artirm Gubaidullin*. Contrasts rule-based symbolic systems (expert systems, logic programming) with data-driven deep learning; explains when explicit rules excel in interpretability and low-data regimes.
* **[Knowledge Representation and Reasoning (2004) ‚Äì Stanford CS227 Notes](https://web.stanford.edu/class/cs227/lectures/notes.html)** ‚Äì *Brachman & Levesque* (textbook); these lecture notes cover logic, semantic networks, frames, description logics, and automated inference.
* **[Learn Prolog Now!](https://lpn.swi-prolog.org/)** ‚Äì *Bruynooghe et al.* Free online Prolog tutorial teaching facts, rules, and queries‚Äîhands-on introduction to first-order logic programming.
* **[A\* Search Algorithm (1968)](https://en.wikipedia.org/wiki/A*_search_algorithm)** ‚Äì *Hart, Nilsson & Raphael*. Wikipedia summary of the original A\* pathfinding algorithm, complete with pseudocode and complexity analysis.
* **[Alpha‚ÄìBeta Pruning (1975)](https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning)** ‚Äì *Knuth & Moore*. Wikipedia overview of minimax search optimization used in game-playing AI.
* **[STRIPS Planner (1971)](https://web.archive.org/web/20170823084059/http://ai.stanford.edu/~nilsson/OnlinePubs-Nils/PublishedPapers/STRIPS.pdf)** ‚Äì *Fikes & Nilsson*. Original Stanford Research Institute memo defining actions via preconditions/effects‚Äîfoundation of classical planning.
* **[OWL 2 Web Ontology Language Overview (2009)](https://www.w3.org/TR/owl2-overview/)** ‚Äì W3C specification for building and querying knowledge graphs and ontologies on the Semantic Web.

## Cognitive Architectures & Cognitive Modeling
*Integrated architectures modeling human cognition: memory, reasoning, learning, and consciousness.*

* **[Extending the Soar Cognitive Architecture (2008)](https://aaai.org/Papers/AAAI/2008/AAAI08-078.pdf)** ‚Äì *John Laird*. Core paper describing Soar‚Äôs production-rule memory, working-memory decision cycle, and chunking learning mechanism.
* **[ACT-R: How ACT-R Works](http://act-r.psy.cmu.edu/)** ‚Äì *John R. Anderson*. Official ACT-R website with free manual and papers on modules for declarative/procedural memory, visual/motor systems, and timing models of human cognition.
* **[40 Years of Cognitive Architectures (2020)](https://arxiv.org/abs/2008.02700)** ‚Äì *Kotseruba & Tsotsos*. Survey of 84 architectures (symbolic, connectionist, hybrid), mapping core cognitive abilities and real-world applications.
* **[Cognitive Architectures for Language Agents (2024)](https://proceedings.mlr.press/v281/sumers24a.html)** ‚Äì *Sumers et al.* TMLR paper introducing CoALA: integrating large language models with production-system memories and decision procedures.
* **[LEIA: Language-Endowed Intelligent Agents (2023)](https://direct.mit.edu/htkm/page/179)** ‚Äì *McShane et al.* MIT Press open-access work presenting hybrid symbolic + data-driven agents designed for transparency, tool use, and human-AI collaboration.
* **[Human and Machine Consciousness (2017)](https://www.openbookpublishers.com/product/781)** ‚Äì *David Gamez*. Open Book Publishers free text exploring theories of consciousness in biological and artificial systems.

## Neuro-Symbolic & Hybrid AI
*Bridging neural networks with symbolic reasoning for robust, explainable systems.*

* **[Neuro-Symbolic AI: A Survey (2023)](https://dl.acm.org/doi/10.1145/3592378)** ‚Äì *Garcez et al.* CACM survey of neural-symbolic frameworks (Neural Theorem Provers, DeepProbLog, Logic Tensor Networks).
* **[Towards Cognitive AI Systems: A Neuro-Symbolic Survey (2024)](https://arxiv.org/abs/2402.05123)** ‚Äì *Hao et al.* ArXiv taxonomy of integration strategies (Neuro‚ÜíSymbolic, Symbolic‚ÜíNeuro, fully integrated loops) for trustworthy AI.
* **[Logical Neural Networks (2020)](https://arxiv.org/abs/2009.02506)** ‚Äì *Riegel et al.* Differentiable logic operators embedded in neural architectures, enabling exact Boolean reasoning in the limit.
* **[Neuro-Symbolic Concept Learner (2019)](https://arxiv.org/abs/1904.07250)** ‚Äì *Mao et al.* NS-CL system combining neural perception with symbolic program induction for CLEVR visual question answering.
* **[IBM Neurologic AI Workshop (2020)](https://www.ibm.com/blogs/research/2020/02/neurologic-ai-workshop/)** ‚Äì IBM Research slides and videos on prototype neuro-symbolic systems by Gary Marcus, Josh Tenenbaum, and others.
* **[Neural LP: Learning to Reason with Logic Programming (2017)](https://arxiv.org/abs/1707.06690)** ‚Äì *Yang et al.* Neural methods for learning logical rules over knowledge graphs.
* **[Neuro-Symbolic Integration for Knowledge Graphs (2022)](https://arxiv.org/abs/2207.07673)** ‚Äì Survey on combining graph neural networks with symbolic reasoning over ontologies.

## Multi-Modal AI (Vision, Language, and More)
*Models that jointly process text, images, audio, and other modalities.*

* **[Multimodal Foundation Models: From Specialists to General-Purpose Assistants (2023)](https://arxiv.org/abs/2307.08007)** ‚Äì *Li et al.* ArXiv survey tracing the evolution from single-task models (captioning) to unified multimodal LLM assistants.
* **[CLIP (2021)](https://arxiv.org/abs/2103.00020)** ‚Äì *Radford et al.* Contrastive pre-training on 400 M image‚Äìtext pairs enabling zero-shot vision tasks via text prompts.
* **[ALIGN (2021)](https://arxiv.org/abs/2102.05918)** ‚Äì *Jia et al.* Google‚Äôs large-scale image‚Äìtext contrastive model on 1 B+ pairs.
* **[BLIP: Bootstrapping Language-Image Pre-training (2022)](https://arxiv.org/abs/2201.12086)** ‚Äì *Li et al.* Unified framework for vision‚Äìlanguage tasks using noisy image‚Äìtext data.
* **[FLAVA (2022)](https://arxiv.org/abs/2203.14239)** ‚Äì *Singh et al.* Facebook‚Äôs foundational model covering vision, language, and their fusion.
* **[SimVLM (2021)](https://arxiv.org/abs/2108.10904)** ‚Äì *Wang et al.* Simple Visual Language Model pre-training with weak supervision for captioning and VQA.
* **[Mind‚Äôs Eye: Vision-Language Navigation (2020)](https://arxiv.org/abs/2003.00512)** ‚Äì *Hao et al.* Survey on agents interpreting language instructions to navigate 3D environments.
* **[A Survey on Multimodal LLMs (2023)](https://arxiv.org/abs/2312.03764)** ‚Äì *Zhang et al.* Overview of extending LLMs with image, audio, and video modalities.
* **[Programming Computer Vision with Python (2012)](https://programmingcomputervision.com/)** ‚Äì *Jan Erik Solem*. Free O‚ÄôReilly-style book on image processing with PIL and OpenCV.
* **[CVPR 2023 Tutorials](https://openaccess.thecvf.com/CVPR2023?day=Tutorials)** ‚Äì Official CVPR page listing tutorials on vision foundation models.
* **[NeurIPS 2022 Tutorials](https://neurips.cc/Conferences/2022/Schedule?type=Tutorials)** ‚Äì NeurIPS schedule page for multimodal and foundational model tutorials.

## Explainability & Model Interpretability
*Techniques and critiques for making AI models transparent and understandable.*

* **[Interpretable Machine Learning (2019)](https://christophm.github.io/interpretable-ml-book/)** ‚Äì *Christoph Molnar*. Free guide covering feature importance, decision trees, LIME, SHAP, saliency maps, and best practices.
* **[Attention Is Not Explanation (2019)](https://arxiv.org/abs/1902.10186)** ‚Äì *Jain & Wallace*. Shows that attention weights in NLP models may not correspond to model reasoning.
* **[The Building Blocks of Interpretability (2018)](https://distill.pub/2018/building-blocks/)** ‚Äì *Olah et al.* Interactive Distill.pub article visualizing internal neuron activations and circuits in CNNs.
* **[SHAP: SHapley Additive exPlanations (2017)](https://arxiv.org/abs/1705.07874)** ‚Äì *Lundberg & Lee*. Game-theoretic framework for local feature attributions.
* **[TCAV: Testing with Concept Activation Vectors (2018)](https://arxiv.org/abs/1711.11279)** ‚Äì *Kim et al.* Probes whether high-level human concepts influence network predictions.
* **[Ethical Artificial Intelligence (2014)](https://arxiv.org/abs/1409.1785)** ‚Äì *Bill Hibbard*. Examines reward hacking, model-based utility, and transparency in agent design.
* **[Model Cards (2019)](https://arxiv.org/abs/1810.03993)** ‚Äì *Mitchell et al.* FAT\* paper on concise documentation of model performance, intended use, and limitations.
* **[Datasheets for Datasets (2018)](https://arxiv.org/abs/1803.09010)** ‚Äì *Gebru et al.* Proposes standardized documentation for dataset provenance and characteristics.

## Ethics, Safety & AI Alignment

*Understanding and mitigating ethical risks, fairness concerns, and alignment challenges.*

* **[Ethical Artificial Intelligence (2014)](https://arxiv.org/abs/1409.1785)** ‚Äì *Bill Hibbard*. Free book-length arXiv treatment of utility-based agents, reward corruption, and instrumental goals.
* **[Concrete Problems in AI Safety (2016)](https://arxiv.org/abs/1606.06565)** ‚Äì *Amodei et al.* OpenAI paper outlining side-effects, reward hacking, oversight, safe exploration, and robustness.
* **[A Tutorial on Fairness in ML (2022)](https://arxiv.org/abs/2201.01729)** ‚Äì *Nargesian et al.* Survey of fairness definitions, bias mitigation, and case studies.
* **[Fairness and Machine Learning (2019)](https://fairmlbook.org/)** ‚Äì *Barocas, Hardt & Narayanan*. Free draft book on social, legal, and technical aspects of algorithmic bias.
* **[The Alignment Problem (2020)](https://brianchristian.org/books/the-alignment-problem/)** ‚Äì *Brian Christian*. Companion site with summaries and interviews on AI alignment issues.
* **[IEEE Ethically Aligned Design (2019)](https://ethicsinaction.ieee.org/)** ‚Äì Multi-author PDF report with guidelines on accountability, privacy, and autonomous systems.
* **[ACM FAccT Conference Proceedings](https://dl.acm.org/conference/facct)** ‚Äì Annual open proceedings on fairness, accountability, and transparency in socio-technical systems.
* **[Stanford ‚ÄúEthics of AI‚Äù Course](https://csai.stanford.edu/education/ethics.html)** ‚Äì Syllabus and readings from Stanford‚Äôs AI ethics classes.
* **[OpenAI Safety Blog](https://openai.com/blog/tag/safety/)** ‚Äì Posts on concrete safety experiments and alignment research.
* **[DeepMind Safety Blog](https://deepmind.com/blog/article/scalable-agent-alignment)** ‚Äì Articles on scalable approaches to aligning advanced agents.
* **[AI Now Institute Reports](https://ainowinstitute.org/reports.html)** ‚Äì Annual free reports on AI‚Äôs societal impacts and policy recommendations.
* **[Stanford HAI AI Index](https://aiindex.stanford.edu/)** ‚Äì Yearly index tracking AI development, adoption, and governance trends.

## Human-AI Interaction & Collaboration
*Design practices and studies for effective, trustworthy human‚ÄìAI partnerships.*

* **[Guidelines for Human‚ÄìAI Interaction (2019)](https://www.microsoft.com/en-us/research/publication/guidelines-for-human-ai-interaction/)** ‚Äì *Amershi et al.* CHI paper with 18 design guidelines; includes Microsoft‚Äôs HAX Toolkit and card deck.
* **[Human-Centered AI Framework (2020)](https://arxiv.org/abs/2001.02805)** ‚Äì *Ben Shneiderman*. Proposes ‚Äúsupertools‚Äù and ‚Äúcentaurs‚Äù that balance high automation with human control.
* **[UX Guidebook for AI Products](https://pair.withgoogle.com/)** ‚Äì Google PAIR‚Äôs free guide on data visualization, recommendations, and trust-design patterns.
* **[Explainable AI for Designers](https://github.com/microsoft/ai-ux-cookbook#explainable-ai)** ‚Äì Microsoft AI UX Cookbook section outlining explanation types and use cases.
* **[Teamwork Between Humans and AI (2016)](https://aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12378)** ‚Äì *Kamar*. AAAI paper on mixed-initiative systems and centaur teams.
* **[Doctors and AI: Trust in ML Diagnostics (2021)](https://dl.acm.org/doi/10.1145/3411764.3445259)** ‚Äì CHI study on how explanation style influences clinician trust.
* **[Effects of Chatbot Personification (2017)](https://arxiv.org/abs/1706.06162)** ‚Äì Examines how giving chatbots personalities affects user engagement and trust.
* **[Human-in-the-Loop ML](https://hiltml.org/)** ‚Äì Blog and resources on active learning, annotation interfaces, and continual improvement.
* **[LabelStudio Documentation](https://labelstud.io/)** ‚Äì Open-source tool guides for designing effective data-labeling workflows.
